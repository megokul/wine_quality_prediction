
ðŸ“¦ Project Structure of: E:\MyProjects\pilotproject

ðŸ“„ .env
ðŸ“„ .gitignore
ðŸ“„ Dockerfile
ðŸ“„ LICENSE
ðŸ“„ README.md
ðŸ“„ app.py
ðŸ“ artifacts/
    ðŸ“ data_ingestion/
        ðŸ“„ data.zip
        ðŸ“„ winequality-red.csv
    ðŸ“ data_transformation/
        ðŸ“„ test.csv
        ðŸ“„ train.csv
    ðŸ“ data_validation/
        ðŸ“„ status.txt
    ðŸ“ model_evaluation/
        ðŸ“„ metrics.json
    ðŸ“ model_prediction/
        ðŸ“„ predictions.csv
    ðŸ“ model_trainer/
        ðŸ“„ model.joblib
ðŸ“ config/
    ðŸ“„ config.yaml
ðŸ“ datasets/
    ðŸ“„ winequality-data.zip
ðŸ“ logs/
    ðŸ“„ app_logs.log
    ðŸ“„ directorygen_logs.log
ðŸ“„ main.py
ðŸ“ mlruns/
    ðŸ“ .trash/
    ðŸ“ 0/
        ðŸ“ 77e0764d77204ebaa86744e1a41e45c8/
            ðŸ“ artifacts/
                ðŸ“ model/
                    ðŸ“„ MLmodel
                    ðŸ“„ conda.yaml
                    ðŸ“„ input_example.json
                    ðŸ“„ model.pkl
                    ðŸ“„ python_env.yaml
                    ðŸ“„ requirements.txt
                    ðŸ“„ serving_input_example.json
        ðŸ“ 99b9d6ed1b854f829f537fb9adc1f361/
            ðŸ“ artifacts/
                ðŸ“ model/
                    ðŸ“„ MLmodel
                    ðŸ“„ conda.yaml
                    ðŸ“„ input_example.json
                    ðŸ“„ model.pkl
                    ðŸ“„ python_env.yaml
                    ðŸ“„ requirements.txt
                    ðŸ“„ serving_input_example.json
        ðŸ“ ed0b7f8679184abcaceb9f320580eac1/
            ðŸ“ artifacts/
ðŸ“„ params.yaml
ðŸ“„ print_structure.py
ðŸ“„ project_dump.py
ðŸ“„ project_template.py
ðŸ“„ requirements.txt
ðŸ“ research/
    ðŸ“„ data_ingestion.ipynb
    ðŸ“„ data_validation.ipynb
    ðŸ“„ model_evaluation.ipynb
    ðŸ“„ research.ipynb
ðŸ“„ schema.yaml
ðŸ“„ setup.py
ðŸ“ src/
    ðŸ“ pilotproject/
        ðŸ“„ __init__.py
        ðŸ“ components/
            ðŸ“„ __init__.py
            ðŸ“„ data_ingestion.py
            ðŸ“„ data_transformation.py
            ðŸ“„ data_validation.py
            ðŸ“„ model_evaluation.py
            ðŸ“„ model_prediction.py
            ðŸ“„ model_trainer.py
        ðŸ“ config/
            ðŸ“„ __init__.py
            ðŸ“„ configuration.py
        ðŸ“ constants/
            ðŸ“„ __init__.py
        ðŸ“ entity/
            ðŸ“„ __init__.py
            ðŸ“„ config_entity.py
        ðŸ“ pipeline/
            ðŸ“„ __init__.py
            ðŸ“„ data_ingestion_pipeline.py
            ðŸ“„ data_transformation_pipeline.py
            ðŸ“„ data_validation_pipeline.py
            ðŸ“„ model_evaluation_pipeline.py
            ðŸ“„ model_trainer_pipeline.py
            ðŸ“„ prediction_pipeline.py
        ðŸ“ utils/
            ðŸ“„ __init__.py
            ðŸ“„ common.py
ðŸ“ templates/
    ðŸ“„ index.html
    ðŸ“„ results.html

--- CODE DUMP | PART 2 of 3 ---


================================================================================
# PY FILE: src\pilotproject\components\model_evaluation.py
================================================================================

from src.pilotproject.config.configuration import ModelEvaluationConfig
import numpy as np
import pandas as pd
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import joblib
import mlflow
import mlflow.sklearn
from urllib.parse import urlparse
from src.pilotproject.utils.common import save_json
from src.pilotproject import logger
from pathlib import Path

class ModelEvaluation:
    """
    Handles evaluation of the trained model on test data and logs metrics using MLflow.

    Responsibilities:
    - Load test data and trained model.
    - Generate regression evaluation metrics (RMSE, MAE, R2).
    - Save evaluation results to JSON.
    - Log model, metrics, and parameters with MLflow.
    """

    def __init__(self, config: ModelEvaluationConfig):
        """
        Initializes the ModelEvaluation class with the given configuration.

        Parameters:
            config (ModelEvaluationConfig): Configuration object with paths and MLflow settings.
        """
        self.config = config

    def eval_metrics(self, actual: pd.Series, preds: np.ndarray) -> tuple:
        """
        Calculates regression metrics: RMSE, MAE, and R2.

        Parameters:
            actual (pd.Series): Actual target values.
            preds (np.ndarray): Predicted values from the model.

        Returns:
            tuple: (rmse, mae, r2) as floats
        """
        rmse = np.sqrt(mean_squared_error(actual, preds))
        mae = mean_absolute_error(actual, preds)
        r2 = r2_score(actual, preds)

        return rmse, mae, r2

    def evaluate_log_with_mlflow(self) -> None:
        """
        Evaluates the model and logs the results using MLflow.

        - Loads the test data and trained model.
        - Calculates evaluation metrics.
        - Saves metrics to disk.
        - Logs metrics, parameters, and model to MLflow.

        Returns:
            None
        """
        try:
            # Load paths and configs from config object
            test_data_path = self.config.test_data_path
            model_path = self.config.model_path
            target_column = self.config.target_column
            mlflow_uri = self.config.mlflow_uri
            test_metric_file_path = self.config.test_metric_file_path
            all_params = self.config.all_params

            # Load the test data
            test_data = pd.read_csv(test_data_path)
            logger.info("Loaded test dataset")

            # Load the trained model
            model = joblib.load(model_path)
            logger.info("Loaded trained model from disk")

            # Split test data into features and target
            x_test = test_data.drop(target_column, axis=1)
            y_test = test_data[[target_column]]

            # Set MLflow tracking URI
            mlflow.set_registry_uri(mlflow_uri)
            tracking_uri_type_store = urlparse(mlflow.get_registry_uri()).scheme

            logger.info("Starting MLflow run")
            with mlflow.start_run():
                preds_test = model.predict(x_test)  # Generate predictions
                rmse, mae, r2 = self.eval_metrics(y_test, preds_test)  # Evaluate metrics
                logger.info("Generated evaluation metrics")

                # Save metrics to JSON
                test_scores = {
                    "rmse": rmse,
                    "mae": mae,
                    "r2": r2
                }

                save_json(Path(test_metric_file_path), test_scores)
                logger.info(f"Saved test metrics to: '{test_metric_file_path}'")

                # Log parameters and metrics to MLflow
                mlflow.log_params(all_params)
                logger.info("Logged model parameters to MLflow")

                mlflow.log_metrics(test_scores)
                logger.info("Logged test metrics to MLflow")

                logger.info(f"MLflow tracking URI type: '{tracking_uri_type_store}'")

                # Register model if not using local file store
                if tracking_uri_type_store != "file":
                    mlflow.sklearn.log_model(
                        model,
                        "model",
                        registered_model_name="ElasticNet_model",
                        input_example=x_test.iloc[:1]
                    )
                else:
                    mlflow.sklearn.log_model(
                        model,
                        "model",
                        input_example=x_test.iloc[:1]
                    )

        except FileNotFoundError as fnf_error:
            logger.error(f"File not found during model evaluation. Details: {fnf_error}")
            raise

        except Exception as e:
            logger.error(f"An unexpected error occurred during model evaluation: {e}")
            raise

================================================================================
# PY FILE: src\pilotproject\components\model_prediction.py
================================================================================

from src.pilotproject.entity.config_entity import ModelPredictionConfig
import joblib
from pathlib import Path
from src.pilotproject import logger
import pandas as pd
from typing import Any
import numpy as np

class ModelPrediction:
    """
    Handles prediction using a trained model and writes output to a CSV file.

    Responsibilities:
    - Load the trained model.
    - Predict based on input features.
    - Format predictions with feature columns.
    - Save results to a prediction file.
    """

    def __init__(self, config: ModelPredictionConfig):
        """
        Initializes the ModelPrediction class with the given configuration.

        Parameters:
            config (ModelPredictionConfig): Contains paths, columns, and prediction output location.
        """
        self.config = config

    def predict(self, data: Any) -> np.ndarray:
        """
        Predicts outcomes using the trained model and saves the result to a file.

        Parameters:
            data (Any): Input data to predict on (e.g., numpy array or compatible DataFrame).

        Returns:
            np.ndarray: Prediction results.
        """
        try:
            model_path = self.config.model_path
            predictions_file_path = self.config.predictions_file_path

            # Extract column names from config
            all_columns = list(self.config.columns.keys())  # Full list of columns from schema

            target_column = self.config.target_column  # Extract target column name

            logger.info("Loading model from path")
            model = joblib.load(Path(model_path))  # Load model

            logger.info("Generating predictions")
            prediction = model.predict(data)  # Perform prediction

            # Remove the target column to get feature columns
            feature_columns = all_columns.copy()
            feature_columns.remove(target_column)

            # Create a DataFrame from the input data using feature columns
            data_with_predictions = pd.DataFrame(data, columns=feature_columns)
            data_with_predictions['quality'] = prediction  # Append predictions as a new column

            predictions_path = Path(predictions_file_path)
            logger.info(f"Writing predictions to: '{predictions_path}'")

            # Append if file exists; otherwise create new file with header
            if predictions_path.exists():
                data_with_predictions.to_csv(predictions_path, mode='a', header=False, index=False)
            else:
                data_with_predictions.to_csv(predictions_path, index=False)

            return prediction

        except FileNotFoundError as fnf_error:
            logger.error(f"Model file not found at: '{self.config.model_path}'. Details: {fnf_error}")
            raise

        except Exception as e:
            logger.error(f"An error occurred during prediction: {e}")
            raise

================================================================================
# PY FILE: src\pilotproject\components\model_trainer.py
================================================================================

from src.pilotproject.entity.config_entity import ModelTrainerConfig
import pandas as pd
from sklearn.linear_model import ElasticNet
import joblib
import os
from src.pilotproject import logger
from typing import NoReturn

class ModelTrainer:
    """
    Handles training of a regression model using ElasticNet.

    Responsibilities:
    - Load training and testing datasets.
    - Split features and target column.
    - Train the ElasticNet model.
    - Save the trained model to disk.
    """

    def __init__(self, config: ModelTrainerConfig):
        """
        Initializes the ModelTrainer with configuration.

        Parameters:
            config (ModelTrainerConfig): Contains training parameters, file paths, and output model location.
        """
        self.config = config

    def train(self) -> NoReturn:
        """
        Trains the ElasticNet model and saves it to a specified path.

        - Loads training and test datasets.
        - Splits data into features and target.
        - Trains an ElasticNet model using configured hyperparameters.
        - Saves the trained model as a joblib file.

        Returns:
            None
        """
        try:
            # Extract paths and hyperparameters from config
            train_data_path = self.config.train_data_path
            test_data_path = self.config.test_data_path
            target_column = self.config.target_column
            alpha = self.config.alpha
            l1_ratio = self.config.l1_ratio
            model_path = os.path.join(self.config.root_dir, self.config.model_name)

            logger.info("Reading training data")
            train_data = pd.read_csv(train_data_path)

            logger.info("Reading test data")
            test_data = pd.read_csv(test_data_path)

            logger.info("Extracting features and target from training data")
            x_train = train_data.drop(target_column, axis=1)  # Input features
            y_train = train_data[[target_column]]             # Target column

            # Initialize and train ElasticNet model
            lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)
            logger.info(f"Training ElasticNet model with alpha={alpha}, l1_ratio={l1_ratio}")
            lr.fit(x_train, y_train)
            logger.info("Model training completed")

            # Save trained model to disk
            joblib.dump(lr, model_path)
            logger.info(f"Trained model saved to: '{model_path}'")

        except FileNotFoundError as fnf_error:
            logger.error(f"One of the dataset files was not found. Details: {fnf_error}")
            raise

        except Exception as e:
            logger.error(f"An error occurred during model training: {e}")
            raise

================================================================================
# PY FILE: src\pilotproject\config\__init__.py
================================================================================



================================================================================
# PY FILE: src\pilotproject\config\configuration.py
================================================================================

import os
from src.pilotproject.constants import * 
from src.pilotproject.utils.common import read_yaml, create_directories
from src.pilotproject.entity.config_entity import (
    DataIngestionConfig, 
    DataValidationConfig, 
    DataTransformationConfig, 
    ModelTrainerConfig, 
    ModelEvaluationConfig,
    ModelPredictionConfig
)

class ConfigurationManager:
    """
    Reads and manages all configuration sections for the pipeline components.

    Responsibilities:
    - Load configuration, parameters, and schema YAML files.
    - Return structured config dataclasses for each pipeline stage.
    - Ensure necessary directories are created before pipeline execution.
    """

    def __init__(
        self,
        config_filepath=CONFIG_FILE_PATH,
        params_filepath=PARAMS_FILE_PATH,
        schema_filepath=SCHEMA_FILE_PATH
    ):
        """
        Initializes the ConfigurationManager by loading YAML files and creating the artifact root directory.
        """
        self.config = read_yaml(config_filepath)
        self.params = read_yaml(params_filepath)
        self.schema = read_yaml(schema_filepath)

        create_directories(self.config.artifacts_root)  # Ensure base artifacts directory exists

    def get_data_ingestion_config(self) -> DataIngestionConfig:
        """
        Prepares and returns configuration for data ingestion.

        Returns:
            DataIngestionConfig: Configuration for the data ingestion stage.
        """
        config = self.config.data_ingestion
        create_directories(config.root_dir)

        data_ingestion_config = DataIngestionConfig(
            root_dir=config.root_dir,
            source_URL=config.source_URL,
            local_data_file=config.local_data_file,
            unzip_dir=config.unzip_dir
        )

        return data_ingestion_config

    def get_data_validation_config(self) -> DataValidationConfig:
        """
        Prepares and returns configuration for data validation.

        Returns:
            DataValidationConfig: Configuration for the data validation stage.
        """
        config = self.config.data_validation
        schema = self.schema.COLUMNS
        create_directories(config.root_dir)

        data_validation_config = DataValidationConfig(
            root_dir=config.root_dir,
            STATUS_FILE=config.STATUS_FILE,
            unzip_data_dir=config.unzip_data_dir,
            all_schema=schema
        )

        return data_validation_config

    def get_data_transformation_config(self) -> DataTransformationConfig:
        """
        Prepares and returns configuration for data transformation.

        Returns:
            DataTransformationConfig: Configuration for the data transformation stage.
        """
        config = self.config.data_transformation
        create_directories(config.root_dir)

        data_transformation_config = DataTransformationConfig(
            root_dir=config.root_dir,
            data_path=config.data_path,
            STATUS_FILE=config.STATUS_FILE
        )

        return data_transformation_config

    def get_model_trainer_config(self) -> ModelTrainerConfig:
        """
        Prepares and returns configuration for model training.

        Returns:
            ModelTrainerConfig: Configuration for the model training stage.
        """
        config = self.config.model_trainer
        params = self.params.ElasticNet
        schema = self.schema.TARGET_COLUMN
        create_directories(config.root_dir)

        model_trainer_config = ModelTrainerConfig(
            root_dir=config.root_dir,
            train_data_path=config.train_data_path,
            test_data_path=config.test_data_path,
            model_name=config.model_name,
            alpha=params.alpha,
            l1_ratio=params.l1_ratio,
            target_column=schema.target_column,
        )

        return model_trainer_config

    def get_model_evaluation_config(self) -> ModelEvaluationConfig:
        """
        Prepares and returns configuration for model evaluation.

        Returns:
            ModelEvaluationConfig: Configuration for the model evaluation stage.
        """
        config = self.config.model_evaluation
        params = self.params.ElasticNet
        schema = self.schema.TARGET_COLUMN
        create_directories(config.root_dir)

        model_evaluation_config = ModelEvaluationConfig(
            root_dir=config.root_dir,
            test_data_path=config.test_data_path,
            model_path=config.model_path,
            test_metric_file_path=config.test_metric_file_path,
            target_column=schema.target_column,
            all_params=params,
            mlflow_uri=os.getenv("MLFLOW_TRACKING_URI")
        )

        return model_evaluation_config

    def get_model_prediction_config(self) -> ModelPredictionConfig:
        """
        Prepares and returns configuration for model prediction.

        Returns:
            ModelPredictionConfig: Configuration for the model prediction stage.
        """
        config = self.config.model_prediction
        col_schema = self.schema.COLUMNS
        target_schema = self.schema.TARGET_COLUMN
        create_directories(config.root_dir)

        model_prediction_config = ModelPredictionConfig(
            root_dir=config.root_dir,
            model_path=config.model_path,
            predictions_file_path=config.predictions_file_path,
            target_column=target_schema.target_column,
            columns=col_schema
        )

        return model_prediction_config

================================================================================
# PY FILE: src\pilotproject\constants\__init__.py
================================================================================

from pathlib import Path

# ==============================
# ðŸ”¹ CONFIGURATION FILE PATHS
# ==============================

# Path to the main configuration YAML file
CONFIG_FILE_PATH = Path("config/config.yaml")

# Path to the parameters file (e.g., model hyperparameters)
PARAMS_FILE_PATH = Path("params.yaml")

# Path to the data schema definition file
SCHEMA_FILE_PATH = Path("schema.yaml")

================================================================================
# PY FILE: src\pilotproject\entity\__init__.py
================================================================================



================================================================================
# PY FILE: src\pilotproject\entity\config_entity.py
================================================================================

from pathlib import Path
from dataclasses import dataclass

@dataclass
class DataIngestionConfig:
    """
    Configuration for data ingestion component.
    """
    root_dir: Path  
    source_URL: str
    local_data_file: Path
    unzip_dir: Path


@dataclass
class DataValidationConfig:
    """
    Configuration for data validation component.
    """
    root_dir: Path
    unzip_data_dir: Path
    STATUS_FILE: Path
    all_schema: dict  # Expected column names and schema


@dataclass
class DataTransformationConfig:
    """
    Configuration for data transformation component.
    """
    root_dir: Path
    data_path: Path
    STATUS_FILE: Path


@dataclass
class ModelTrainerConfig:
    """
    Configuration for model training component.
    """
    root_dir: Path
    train_data_path: Path
    test_data_path: Path
    model_name: str  # File name to save the trained model
    alpha: float     # Hyperparameter for ElasticNet
    l1_ratio: float  # Hyperparameter for ElasticNet
    target_column: dict


@dataclass
class ModelEvaluationConfig:
    """
    Configuration for model evaluation component.
    """
    root_dir: Path
    test_data_path: Path
    model_path: Path
    test_metric_file_path: Path
    target_column: dict
    mlflow_uri: str
    all_params: dict  # All model parameters to log with MLflow


@dataclass
class ModelPredictionConfig:
    """
    Configuration for model prediction component.
    """
    root_dir: Path
    model_path: Path
    predictions_file_path: Path
    target_column: str  # Name of the column being predicted
    columns: dict       # All input feature columns (from schema)

================================================================================
# PY FILE: src\pilotproject\pipeline\__init__.py
================================================================================



================================================================================
# PY FILE: src\pilotproject\pipeline\data_ingestion_pipeline.py
================================================================================

from src.pilotproject.config.configuration import ConfigurationManager
from src.pilotproject.components.data_ingestion import DataIngestion
from src.pilotproject import logger

STAGE_NAME = "Data Ingestion Stage"

class DataIngestionPipeline:
    """
    Orchestrates the data ingestion stage of the pipeline.

    Responsibilities:
    - Loads the data ingestion configuration.
    - Executes downloading and unzipping of raw data.
    """

    def __init__(self):
        pass

    def initiate_data_ingestion(self):
        """
        Executes the data ingestion workflow:
        - Retrieves configuration for data ingestion.
        - Downloads data if not already present.
        - Extracts the zip file to a specified directory.
        """
        config = ConfigurationManager()
        data_ingestion_config = config.get_data_ingestion_config()
        data_ingestion = DataIngestion(data_ingestion_config)
        data_ingestion.download_file()
        data_ingestion.extract_zip()


if __name__ == '__main__':
    try:
        logger.info(f">>>>>> Stage: {STAGE_NAME} started <<<<<<")
        obj = DataIngestionPipeline()
        obj.initiate_data_ingestion()
        logger.info(f">>>>>> Stage: {STAGE_NAME} completed <<<<<<\n{'x' * 10}")
    except Exception as e:
        logger.exception(e)
        raise

================================================================================
# PY FILE: src\pilotproject\pipeline\data_transformation_pipeline.py
================================================================================

from src.pilotproject.config.configuration import ConfigurationManager
from src.pilotproject.components.data_transformation import DataTransformation
from src.pilotproject import logger

STAGE_NAME = "Data Transformation"

class DataTransformationPipeline:
    """
    Orchestrates the data transformation stage of the pipeline.

    Responsibilities:
    - Reads validation status from file.
    - If validation passes, proceeds with train-test split.
    """

    def __init__(self):
        pass

    def initiate_data_transformation(self):
        """
        Executes the data transformation workflow:
        - Checks validation status from status file.
        - If valid, splits data into train and test sets.
        - If invalid, logs error and raises exception.
        """
        config = ConfigurationManager()
        data_transformation_config = config.get_data_transformation_config()
        STATUS_FILE = data_transformation_config.STATUS_FILE

        logger.info("Checking validation status...")
        with open(STATUS_FILE, 'r') as file:
            validation_status = file.read().split(" ")[-1]

            if validation_status == 'True':
                logger.info(f"Validation status: '{validation_status}' â€” proceeding with transformation")
                data_transformation = DataTransformation(data_transformation_config)
                data_transformation.train_test_splitting()
            else:
                logger.info(f"Validation status: '{validation_status}' â€” stopping pipeline")
                raise Exception("Data schema is not valid")


if __name__ == '__main__':
    try:
        logger.info(f">>>>>> Stage: {STAGE_NAME} started <<<<<<")
        obj = DataTransformationPipeline()
        obj.initiate_data_transformation()
        logger.info(f">>>>>> Stage: {STAGE_NAME} completed <<<<<<\n{'x' * 10}")
    except Exception as e:
        logger.exception(e)
        raise
