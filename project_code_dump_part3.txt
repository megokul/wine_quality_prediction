
ðŸ“¦ Project Structure of: E:\MyProjects\pilotproject

ðŸ“„ .env
ðŸ“„ .gitignore
ðŸ“„ Dockerfile
ðŸ“„ LICENSE
ðŸ“„ README.md
ðŸ“„ app.py
ðŸ“ artifacts/
    ðŸ“ data_ingestion/
        ðŸ“„ data.zip
        ðŸ“„ winequality-red.csv
    ðŸ“ data_transformation/
        ðŸ“„ test.csv
        ðŸ“„ train.csv
    ðŸ“ data_validation/
        ðŸ“„ status.txt
    ðŸ“ model_evaluation/
        ðŸ“„ metrics.json
    ðŸ“ model_prediction/
        ðŸ“„ predictions.csv
    ðŸ“ model_trainer/
        ðŸ“„ model.joblib
ðŸ“ config/
    ðŸ“„ config.yaml
ðŸ“ datasets/
    ðŸ“„ winequality-data.zip
ðŸ“ logs/
    ðŸ“„ app_logs.log
    ðŸ“„ directorygen_logs.log
ðŸ“„ main.py
ðŸ“ mlruns/
    ðŸ“ .trash/
    ðŸ“ 0/
        ðŸ“ 77e0764d77204ebaa86744e1a41e45c8/
            ðŸ“ artifacts/
                ðŸ“ model/
                    ðŸ“„ MLmodel
                    ðŸ“„ conda.yaml
                    ðŸ“„ input_example.json
                    ðŸ“„ model.pkl
                    ðŸ“„ python_env.yaml
                    ðŸ“„ requirements.txt
                    ðŸ“„ serving_input_example.json
        ðŸ“ 99b9d6ed1b854f829f537fb9adc1f361/
            ðŸ“ artifacts/
                ðŸ“ model/
                    ðŸ“„ MLmodel
                    ðŸ“„ conda.yaml
                    ðŸ“„ input_example.json
                    ðŸ“„ model.pkl
                    ðŸ“„ python_env.yaml
                    ðŸ“„ requirements.txt
                    ðŸ“„ serving_input_example.json
        ðŸ“ ed0b7f8679184abcaceb9f320580eac1/
            ðŸ“ artifacts/
ðŸ“„ params.yaml
ðŸ“„ print_structure.py
ðŸ“„ project_dump.py
ðŸ“„ project_template.py
ðŸ“„ requirements.txt
ðŸ“ research/
    ðŸ“„ data_ingestion.ipynb
    ðŸ“„ data_validation.ipynb
    ðŸ“„ model_evaluation.ipynb
    ðŸ“„ research.ipynb
ðŸ“„ schema.yaml
ðŸ“„ setup.py
ðŸ“ src/
    ðŸ“ pilotproject/
        ðŸ“„ __init__.py
        ðŸ“ components/
            ðŸ“„ __init__.py
            ðŸ“„ data_ingestion.py
            ðŸ“„ data_transformation.py
            ðŸ“„ data_validation.py
            ðŸ“„ model_evaluation.py
            ðŸ“„ model_prediction.py
            ðŸ“„ model_trainer.py
        ðŸ“ config/
            ðŸ“„ __init__.py
            ðŸ“„ configuration.py
        ðŸ“ constants/
            ðŸ“„ __init__.py
        ðŸ“ entity/
            ðŸ“„ __init__.py
            ðŸ“„ config_entity.py
        ðŸ“ pipeline/
            ðŸ“„ __init__.py
            ðŸ“„ data_ingestion_pipeline.py
            ðŸ“„ data_transformation_pipeline.py
            ðŸ“„ data_validation_pipeline.py
            ðŸ“„ model_evaluation_pipeline.py
            ðŸ“„ model_trainer_pipeline.py
            ðŸ“„ prediction_pipeline.py
        ðŸ“ utils/
            ðŸ“„ __init__.py
            ðŸ“„ common.py
ðŸ“ templates/
    ðŸ“„ index.html
    ðŸ“„ results.html

--- CODE DUMP | PART 3 of 3 ---


================================================================================
# PY FILE: src\pilotproject\pipeline\data_validation_pipeline.py
================================================================================

from src.pilotproject.components.data_validation import DataValidation
from src.pilotproject.config.configuration import ConfigurationManager
from src.pilotproject import logger

STAGE_NAME = "Data Validation Stage"

class DataValidationPipeline:
    """
    Orchestrates the data validation stage of the pipeline.

    Responsibilities:
    - Loads validation configuration.
    - Executes schema validation on the raw dataset.
    """

    def __init__(self):
        pass

    def initiate_data_validation(self):
        """
        Executes the data validation workflow:
        - Retrieves config.
        - Performs column/schema validation.
        """
        config = ConfigurationManager()
        data_validation_config = config.get_data_validation_config()
        data_validation = DataValidation(config=data_validation_config)
        data_validation.validate_all_columns()


if __name__ == '__main__':
    try:
        logger.info(f">>>>>> Stage: {STAGE_NAME} started <<<<<<")
        obj = DataValidationPipeline()
        obj.initiate_data_validation()
        logger.info(f">>>>>> Stage: {STAGE_NAME} completed <<<<<<\n{'x' * 10}")
    except Exception as e:
        logger.exception(e)
        raise

================================================================================
# PY FILE: src\pilotproject\pipeline\model_evaluation_pipeline.py
================================================================================

from src.pilotproject.config.configuration import ConfigurationManager
from src.pilotproject.components.model_evaluation import ModelEvaluation
from src.pilotproject import logger

STAGE_NAME = "Model Evaluation Stage"

class ModelEvaluationPipeline:
    """
    Orchestrates the model evaluation stage of the pipeline.

    Responsibilities:
    - Loads model evaluation configuration.
    - Evaluates the model using test data.
    - Logs metrics and model using MLflow.
    """

    def __init__(self):
        pass

    def initiate_model_evaluation(self):
        """
        Executes the model evaluation workflow:
        - Loads test data and trained model.
        - Computes evaluation metrics.
        - Logs parameters, metrics, and model to MLflow.
        """
        config = ConfigurationManager()
        model_evaluation_config = config.get_model_evaluation_config()
        model_evaluation = ModelEvaluation(model_evaluation_config)
        model_evaluation.evaluate_log_with_mlflow()


if __name__ == '__main__':
    try:
        logger.info(f">>>>>> Stage: {STAGE_NAME} started <<<<<<")
        obj = ModelEvaluationPipeline()
        obj.initiate_model_evaluation()
        logger.info(f">>>>>> Stage: {STAGE_NAME} completed <<<<<<\n{'x' * 10}")
    except Exception as e:
        logger.exception(e)
        raise

================================================================================
# PY FILE: src\pilotproject\pipeline\model_trainer_pipeline.py
================================================================================

from src.pilotproject.config.configuration import ConfigurationManager
from src.pilotproject.components.model_trainer import ModelTrainer
from src.pilotproject import logger

STAGE_NAME = "Model Trainer Stage"

class ModelTrainerPipeline:
    """
    Orchestrates the model training stage of the pipeline.

    Responsibilities:
    - Loads training configuration and data.
    - Trains the model using the specified parameters.
    - Saves the trained model to disk.
    """

    def __init__(self):
        pass

    def initiate_model_trainer(self):
        """
        Executes the model training workflow:
        - Retrieves configuration for model training.
        - Initializes and trains the model.
        - Saves the trained model file.
        """
        config = ConfigurationManager()
        model_trainer_config = config.get_model_trainer_config()
        model_trainer = ModelTrainer(model_trainer_config)
        model_trainer.train()


if __name__ == '__main__':
    try:
        logger.info(f">>>>>> Stage: {STAGE_NAME} started <<<<<<")
        obj = ModelTrainerPipeline()
        obj.initiate_model_trainer()
        logger.info(f">>>>>> Stage: {STAGE_NAME} completed <<<<<<\n{'x' * 10}")
    except Exception as e:
        logger.exception(e)
        raise

================================================================================
# PY FILE: src\pilotproject\pipeline\prediction_pipeline.py
================================================================================

from src.pilotproject.config.configuration import ConfigurationManager
from src.pilotproject.components.model_prediction import ModelPrediction

class PredictionPipeline:
    """
    Orchestrates the model prediction stage of the pipeline.

    Responsibilities:
    - Loads model prediction configuration.
    - Accepts input data and returns predictions.
    """

    def __init__(self):
        pass

    def initiate_prediction(self, data) -> list:
        """
        Executes the model prediction workflow.

        Parameters:
            data: Input features to be passed into the trained model for prediction.

        Returns:
            list: Prediction results generated by the model.
        """
        config = ConfigurationManager()
        model_prediction_config = config.get_model_prediction_config()
        model_prediction = ModelPrediction(model_prediction_config)
        prediction = model_prediction.predict(data)

        return prediction

================================================================================
# PY FILE: src\pilotproject\utils\__init__.py
================================================================================



================================================================================
# PY FILE: src\pilotproject\utils\common.py
================================================================================

import os
import yaml
from src.pilotproject import logger
import json
import joblib
from ensure import ensure_annotations
from box import ConfigBox
from pathlib import Path
from typing import Any
from box.exceptions import BoxValueError

@ensure_annotations
def read_yaml(path_to_yaml: Path) -> ConfigBox:
    """
    Reads a YAML file and returns its content as a Configbox object.

    Args:
        path_to_yaml (Path): Path to the YAML file.

    Returns:
        Configbox: Parsed content of the YAML file.

    Raises:
        ValueError: If the YAML file is empty.
        Exception: If any other error occurs during reading the YAML file.
    """
    try:
        with open(path_to_yaml) as yaml_file:  # Open YAML file
            content = yaml.safe_load(yaml_file)  # Load content safely to prevent code execution
            logger.info(f"yaml file: '{path_to_yaml}' loaded successfully")  # Log successful loading
            return ConfigBox(content)  # Convert loaded data to Configbox object for easy access
    except BoxValueError:
        raise ValueError("yaml file is empty")  # Handle case where YAML content is empty
    except Exception as e:
        raise e  # Propagate other exceptions


@ensure_annotations
def create_directories(*path_to_directories, verbose=True):
    """
    Creates directories from the provided list.

    Args:
        path_to_directories (list): List of directory paths.
        verbose (bool, optional): Enables logging of created directories. Defaults to True.
    """
    for path in path_to_directories:
        os.makedirs(path, exist_ok=True)  # Create directories, ignoring if they already exist
        if verbose:
            logger.info(f"created directory at: '{path}'")  # Log directory creation


@ensure_annotations
def save_json(path: Path, data: dict):
    """
    Saves a dictionary to a JSON file.

    Args:
        path (Path): Path to the output JSON file.
        data (dict): Dictionary to save.
    """
    with open(path, 'w') as file:  # Open file in write mode
        json.dump(data, file, indent=4)  # Write data as formatted JSON

    logger.info(f"JSON file saved at: '{path}'")  # Log JSON file creation


@ensure_annotations
def load_json(path: Path) -> ConfigBox:
    """
    Loads a JSON file and returns its content as a Configbox object.

    Args:
        path (Path): Path to the JSON file.

    Returns:
        Configbox: Parsed content of the JSON file.
    """
    with open(path) as file:  # Open JSON file
        content = json.load(file)  # Load JSON content

    logger.info(f"JSON file loaded successfully from: '{path}'")  # Log successful load
    return ConfigBox(content)  # Convert loaded data to Configbox object


@ensure_annotations
def save_bin(path: Path, data: Any):
    """
    Saves a Python object in binary format using joblib.

    Args:
        path (Path): Path to the binary file.
        data (Any): Python object to serialize.
    """
    joblib.dump(value=data, filename=path)  # Serialize and save the Python object
    logger.info(f"Binary file saved at: '{path}'")  # Log binary file creation


@ensure_annotations
def load_bin(path: Path) -> Any:
    """
    Loads a Python object from a binary file.

    Args:
        path (Path): Path to the binary file.

    Returns:
        Any: Python object loaded from the binary file.
    """
    data = joblib.load(path)  # Load Python object from binary file
    logger.info(f"Binary file loaded from: '{path}'")  # Log successful load
    return data

================================================================================
# YAML FILE: config\config.yaml
================================================================================

# ==============================
# Project Artifacts Root
# ==============================

# Directory where all pipeline-related outputs will be saved
artifacts_root: artifacts

# ==============================
# Data Ingestion Configuration
# ==============================

data_ingestion:
  # Directory for all data ingestion outputs
  root_dir: artifacts/data_ingestion
  
  # Remote URL to download the dataset
  source_URL: https://github.com/krishnaik06/datasets/raw/refs/heads/main/winequality-data.zip
  
  # Path to save the downloaded zip file
  local_data_file: artifacts/data_ingestion/data.zip
  
  # Directory to extract the contents of the zip file
  unzip_dir: artifacts/data_ingestion

# ==============================
# Data Validation Configuration
# ==============================

data_validation:
  # Directory to store data validation outputs
  root_dir: artifacts/data_validation

  # Path to the raw CSV data after unzipping
  unzip_data_dir: artifacts/data_ingestion/winequality-red.csv

  # Path to a status file that tracks validation result
  STATUS_FILE: artifacts/data_validation/status.txt

# ==============================
# Data Transformation Configuration
# ==============================

data_transformation:
  # Directory to store transformed data
  root_dir: artifacts/data_transformation

  # Path to the raw input data
  data_path: artifacts/data_ingestion/winequality-red.csv

  # Path to status file (shared with validation status)
  STATUS_FILE: artifacts/data_validation/status.txt

# ==============================
# Model Training Configuration
# ==============================

model_trainer:
  # Directory to save trained model and training logs
  root_dir: artifacts/model_trainer

  # Path to training dataset
  train_data_path: artifacts/data_transformation/train.csv

  # Path to testing dataset
  test_data_path: artifacts/data_transformation/test.csv

  # Filename for the trained model
  model_name: model.joblib

# ==============================
# Model Evaluation Configuration
# ==============================

model_evaluation:
  # Directory for model evaluation outputs
  root_dir: artifacts/model_evaluation

  # Path to testing data used for evaluation
  test_data_path: artifacts/data_transformation/test.csv

  # Path to the trained model file
  model_path: artifacts/model_trainer/model.joblib

  # File to save evaluation metrics like accuracy, F1, etc.
  test_metric_file_path: artifacts/model_evaluation/metrics.json

# ==============================
# Model Prediction Configuration
# ==============================

model_prediction:
  # Directory to store prediction outputs
  root_dir: artifacts/model_prediction

  # Path to the trained model for inference
  model_path: artifacts/model_trainer/model.joblib

  # Output file path for storing predictions
  predictions_file_path: artifacts/model_prediction/predictions.csv

================================================================================
# YAML FILE: params.yaml
================================================================================

ElasticNet:
  alpha: 0.2
  l1_ratio: 0.1

================================================================================
# YAML FILE: schema.yaml
================================================================================

COLUMNS:
  fixed acidity: float64
  volatile acidity: float64
  citric acid: float64
  residual sugar: float64
  chlorides: float64
  free sulfur dioxide: float64
  total sulfur dioxide: float64
  density: float64
  pH: float64
  sulphates: float64
  alcohol: float64
  quality: int64

TARGET_COLUMN:
  target_column: quality
